{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f501271-82be-46b9-a875-e02ccae263ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup CUDA\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98666f2-56a7-4c01-aeb3-0d9fd785de73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/bin:/bin:/usr/bin:/usr/local/cuda/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add the directory containing the executable to the PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/cuda/bin\"\n",
    "\n",
    "# Check if the directory is added to the PATH\n",
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662d3097-8d04-4bf4-ba06-bd0937d67fe7",
   "metadata": {},
   "source": [
    "## Pure C implementation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acbad2ce-9345-41ea-99e2-f9b6b7222517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C_max.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile C_max.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "\n",
    "#define MIN_VAL -20\n",
    "#define MAX_VAL 20\n",
    "#define RUN_COUNT 30\n",
    "\n",
    "#define print_array(type, n, arr, fmt) \\\n",
    "    do { \\\n",
    "        size_t i; \\\n",
    "        type *array = (type *)arr; \\\n",
    "        printf(\"[\"); \\\n",
    "        for (i = 0; i < 5; i++) { \\\n",
    "            printf(fmt, array[i]); \\\n",
    "        } \\\n",
    "        printf(\"..., \"); \\\n",
    "        for (i = n - 5; i < n; i++) { \\\n",
    "            printf(fmt, array[i]); \\\n",
    "        } \\\n",
    "        printf(\"\\b\\b]\\n\"); \\\n",
    "    } while (0)\n",
    "\n",
    "// C implementation\n",
    "void C_max(size_t n, float A[], float B[], float C[], int idx[]) {\n",
    "    for (size_t i = 0; i < n; i++) {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// Dynamically allocates an array of size n and fills it with random float values\n",
    "// WARNING: Pointer returned by this function must be freed!\n",
    "float* malloc_rand(size_t n) {\n",
    "    float* array = (float*) malloc(n * sizeof(float));\n",
    "\n",
    "    // Gracefully exit in case malloc() fails\n",
    "    if (array == NULL)\n",
    "        return NULL;\n",
    "\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        // Generates a random floating-point value between MIN_VAL and MAX_VAL\n",
    "        array[i] = MIN_VAL + ((float) rand() / (float) RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "    }\n",
    "\n",
    "    return array;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    srand(339);\n",
    "    size_t size = 1 << 28;\n",
    "\n",
    "    float* A = malloc_rand(size);\n",
    "    float* B = malloc_rand(size);\n",
    "    float* C = (float*) malloc(size * sizeof(float));\n",
    "    int* idx = (int*) malloc(size * sizeof(float));\n",
    "\n",
    "    // Print input arrays\n",
    "    \n",
    "    printf(\"A = \");\n",
    "    print_array(float, size, A, \"%.2f, \");\n",
    "    printf(\"B = \");\n",
    "    print_array(float, size, B, \"%.2f, \");\n",
    "    \n",
    "    printf(\"\\nExecuting...\\n\\n\");\n",
    "    \n",
    "    // Time execution\n",
    "        \n",
    "    clock_t start, end;\n",
    "    long long int total_execution_time = 0;\n",
    "    double avg_execution_time;\n",
    "\n",
    "    for (int i = 0; i < RUN_COUNT; i++) {\n",
    "        start = clock();\n",
    "        C_max(size, A, B, C, idx);\n",
    "        end = clock();\n",
    "        total_execution_time += ((double) (end - start)) * 1E3 / CLOCKS_PER_SEC;\n",
    "    }\n",
    "\n",
    "    avg_execution_time = 1.0 * total_execution_time / RUN_COUNT;\n",
    "\n",
    "    printf(\"\\n===== size = %zu =====\\n\", size);\n",
    "\n",
    "    printf(\"Average execution time over %d runs: %.6f ms\\n\",\n",
    "        RUN_COUNT, avg_execution_time);\n",
    "    \n",
    "    // Print results\n",
    "    \n",
    "    printf(\"C = \");\n",
    "    print_array(float, size, C, \"%.2f, \");\n",
    "\n",
    "    printf(\"idx = \");\n",
    "    print_array(int, size, idx, \"%d, \");\n",
    "\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C);\n",
    "    free(idx);\n",
    "        \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb1f18e-e17d-473d-b720-9ca9272b311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcc C_max.c -o C_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7bf26c6-9061-4846-8659-f8b3abb5e56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = [18.88, 0.47, 3.11, 19.78, 4.43, ..., 1.76, 8.19, -4.65, 1.50, -4.35]\n",
      "B = [17.55, -10.48, 13.66, -1.62, -6.12, ..., 12.83, -12.63, 17.10, 15.21, -0.77]\n",
      "\n",
      "Executing...\n",
      "\n",
      "\n",
      "===== size = 268435456 =====\n",
      "Average execution time over 30 runs: 5523.866667 ms\n",
      "C = [18.88, 0.47, 13.66, 19.78, 4.43, ..., 12.83, 8.19, 17.10, 15.21, -0.77]\n",
      "idx = [0, 0, 1, 0, 0, ..., 1, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./C_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18cbde8-c4fc-44c0-bee5-413756f359e9",
   "metadata": {
    "id": "L-V-aZxHQMbH"
   },
   "source": [
    "## Grid-stride CUDA\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1ad124-533c-40bc-9093-6d4f6306bd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_max.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_max.cu\n",
    "#include<stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define MIN_VAL -20\n",
    "#define MAX_VAL 20\n",
    "\n",
    "__global__\n",
    "void cuda_max(size_t n, float* max_arr, float* A, float* B, int* idx) {\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride) {\n",
    "        max_arr[i] = (A[i] > B[i]) ? A[i] : B[i];\n",
    "        idx[i] = (A[i] >= B[i]) ? 0 : 1;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const size_t ARRAY_SIZE = 1 << 28;\n",
    "    const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    "    \n",
    "    // Execute 30 times\n",
    "    const size_t loope = 30;\n",
    "    \n",
    "    // Declare arrays\n",
    "    float *A, *B, *max_arr;\n",
    "    int* idx;\n",
    "\n",
    "    cudaMallocManaged(&A, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&B, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&max_arr, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&idx, ARRAY_BYTES);\n",
    "    \n",
    "    // Init array\n",
    "    for (size_t i = 0; i < ARRAY_SIZE; i++) {\n",
    "        A[i] =\n",
    "            MIN_VAL + ((float)rand() / (float)RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "        B[i] =\n",
    "            MIN_VAL + ((float)rand() / (float)RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "    }\n",
    "    \n",
    "    // Setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads - 1) / numThreads;\n",
    "    \n",
    "    printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "    printf(\"numBlocks = %lu, numThreads = %lu \\n\", numBlocks, numThreads);\n",
    "\n",
    "    // Execute kernel\n",
    "    for (size_t i = 0; i < loope; i++)\n",
    "        cuda_max<<<numBlocks, numThreads>>>(ARRAY_SIZE, max_arr, A, B, idx);\n",
    "    \n",
    "    // Barrier\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Error checking\n",
    "    size_t err_count = 0;\n",
    "    for (size_t i = 0; i < ARRAY_SIZE; i++) {\n",
    "        if (((A[i] > B[i]) ? A[i] : B[i]) != max_arr[i]) err_count++;\n",
    "    }\n",
    "    printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "    \n",
    "    // Free memory\n",
    "    cudaFree(A);\n",
    "    cudaFree(B);\n",
    "    cudaFree(max_arr);\n",
    "    cudaFree(idx);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a26f1e39-390a-4007-9684-439792e30803",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_max.cu -o CUDA_max -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5d14f22-634d-4d55-988c-4028232e37c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1064265== NVPROF is profiling process 1064265, command: ./CUDA_max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1064265== Profiling application: ./CUDA_max\n",
      "==1064265== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  12.8406s        30  428.02ms  20.567ms  12.2354s  cuda_max(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   87.09%  12.8434s         1  12.8434s  12.8434s  12.8434s  cudaDeviceSynchronize\n",
      "                   10.27%  1.51448s         4  378.62ms  89.217us  1.51297s  cudaMallocManaged\n",
      "                    2.56%  377.99ms         4  94.496ms  33.575ms  117.20ms  cudaFree\n",
      "                    0.07%  9.8796ms        30  329.32us  13.221us  9.0893ms  cudaLaunchKernel\n",
      "                    0.00%  684.64us       114  6.0050us     194ns  314.68us  cuDeviceGetAttribute\n",
      "                    0.00%  229.76us         1  229.76us  229.76us  229.76us  cuDeviceGetName\n",
      "                    0.00%  64.804us         1  64.804us  64.804us  64.804us  cuDeviceTotalMem\n",
      "                    0.00%  40.534us         1  40.534us  40.534us  40.534us  cuDeviceGetPCIBusId\n",
      "                    0.00%  9.4670us         3  3.1550us     272ns  6.0700us  cuDeviceGetCount\n",
      "                    0.00%  7.9630us         2  3.9810us     860ns  7.1030us  cuDeviceGet\n",
      "                    0.00%  1.5820us         1  1.5820us  1.5820us  1.5820us  cuDeviceGetUuid\n",
      "                    0.00%     485ns         1     485ns     485ns     485ns  cuModuleGetLoadingMode\n",
      "\n",
      "==1064265== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "   30741  29.564KB  4.0000KB  0.9961MB  887.5273MB  284.5978ms  Host To Device\n",
      "   18428  170.70KB  4.0000KB  0.9961MB  2.999878GB   1.100444s  Device To Host\n",
      "    3471         -         -         -           -   3.881541s  Gpu page fault groups\n",
      "Total CPU Page faults: 15359\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20982b76-f3a6-4374-9764-64257217a081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Device-side CUDA Event completion trace is currently enabled.\n",
      "         This may increase runtime overhead and the likelihood of false\n",
      "         dependencies across CUDA Streams. If you wish to avoid this, please\n",
      "         disable the feature with --cuda-event-trace=false.\n",
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n",
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-c3f1.qdstrm'\n",
      "[1/1] [========================100%] CUDA_max.nsys-rep\n",
      "Generated:\n",
      "\t/home/jupyter-lorenz_marqueses@d-08e53/CUDA_max.nsys-rep\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nsys profile  -o CUDA_max ./CUDA_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77346d78-718c-4c27-9a67-b07653505dde",
   "metadata": {
    "id": "L-V-aZxHQMbH"
   },
   "source": [
    "## Grid-stride CUDA (prefetch)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bafd92a-91eb-41b0-9ead-4876446bdbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_max2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_max2.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define MIN_VAL -20\n",
    "#define MAX_VAL 20\n",
    "\n",
    "__global__\n",
    "void cuda_max(size_t n, float *max_arr, float *A, float *B, int *idx) {\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride) {\n",
    "        max_arr[i] = (A[i] > B[i]) ? A[i] : B[i];\n",
    "        idx[i] = (A[i] >= B[i]) ? 0 : 1;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const size_t ARRAY_SIZE = 1 << 28;\n",
    "    const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    "\n",
    "    // Execute 30 times\n",
    "    const size_t loope = 30;\n",
    "    \n",
    "    // Declare array\n",
    "    float *A, *B, *max_arr;\n",
    "    int *idx;\n",
    "\n",
    "    cudaMallocManaged(&A, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&B, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&max_arr, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&idx, ARRAY_BYTES);\n",
    "    \n",
    "    // Get GPU ID\n",
    "    int device = -1;\n",
    "    cudaGetDevice(&device);\n",
    "    \n",
    "    // Init array\n",
    "    for (size_t i = 0; i < ARRAY_SIZE; i++) {\n",
    "        A[i] =\n",
    "            MIN_VAL + ((float)rand() / (float)RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "        B[i] =\n",
    "            MIN_VAL + ((float)rand() / (float)RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "    }\n",
    "\n",
    "    // Prefetch CPU -> GPU\n",
    "    cudaMemPrefetchAsync(A, ARRAY_BYTES, device, NULL);\n",
    "    cudaMemPrefetchAsync(B, ARRAY_BYTES, device, NULL);\n",
    "    \n",
    "    // Setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads - 1) / numThreads;\n",
    "    printf(\"*** function = MAX\\n\");\n",
    "    printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "    printf(\"numBlocks = %lu, numThreads = %lu \\n\", numBlocks, numThreads);\n",
    "    for (size_t i = 0; i < loope; i++)\n",
    "        cuda_max<<<numBlocks, numThreads>>>(ARRAY_SIZE, max_arr, A, B, idx);\n",
    "    \n",
    "    // Barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    // Prefetch GPU -> CPU\n",
    "    cudaMemPrefetchAsync(max_arr, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "    cudaMemPrefetchAsync(A, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "    cudaMemPrefetchAsync(B, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "    cudaMemPrefetchAsync(idx, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "\n",
    "    // Error checking\n",
    "    size_t err_count = 0;\n",
    "    for (size_t i = 0; i < ARRAY_SIZE; i++) {\n",
    "        if (((A[i] > B[i]) ? A[i] : B[i]) != max_arr[i]) err_count++;\n",
    "    }\n",
    "    printf(\"Error count (CUDA program): %zu\\n\", err_count);\n",
    "    \n",
    "    // Free memory\n",
    "    cudaFree(A);\n",
    "    cudaFree(B);\n",
    "    cudaFree(max_arr);\n",
    "    cudaFree(idx);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26130961-703f-42e1-82df-d314a47f5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_max2.cu -o CUDA_max2 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e99f4c2-fa30-4e85-afa7-e41addf513c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1064483== NVPROF is profiling process 1064483, command: ./CUDA_max2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = MAX\n",
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Error count (CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1064483== Profiling application: ./CUDA_max2\n",
      "==1064483== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  5.67483s        30  189.16ms  20.521ms  5.07373s  cuda_max(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   52.25%  5.67741s         1  5.67741s  5.67741s  5.67741s  cudaDeviceSynchronize\n",
      "                   21.83%  2.37187s         6  395.31ms  1.9833ms  757.97ms  cudaMemPrefetchAsync\n",
      "                   18.30%  1.98823s         4  497.06ms  61.604us  1.98743s  cudaMallocManaged\n",
      "                    5.21%  566.65ms         4  141.66ms  100.10ms  165.56ms  cudaFree\n",
      "                    2.41%  261.54ms        30  8.7178ms  11.757us  260.68ms  cudaLaunchKernel\n",
      "                    0.01%  796.19us       114  6.9840us     149ns  339.10us  cuDeviceGetAttribute\n",
      "                    0.00%  306.64us         1  306.64us  306.64us  306.64us  cuDeviceGetName\n",
      "                    0.00%  36.056us         1  36.056us  36.056us  36.056us  cuDeviceTotalMem\n",
      "                    0.00%  20.800us         1  20.800us  20.800us  20.800us  cuDeviceGetPCIBusId\n",
      "                    0.00%  16.324us         1  16.324us  16.324us  16.324us  cudaGetDevice\n",
      "                    0.00%  8.9640us         2  4.4820us     250ns  8.7140us  cuDeviceGet\n",
      "                    0.00%  6.1290us         3  2.0430us     212ns  5.6080us  cuDeviceGetCount\n",
      "                    0.00%     627ns         1     627ns     627ns     627ns  cuModuleGetLoadingMode\n",
      "                    0.00%     341ns         1     341ns     341ns     341ns  cuDeviceGetUuid\n",
      "\n",
      "==1064483== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "    1024  2.0000MB  2.0000MB  2.0000MB  2.000000GB  345.4292ms  Host To Device\n",
      "    2048  2.0000MB  2.0000MB  2.0000MB  4.000000GB   2.039119s  Device To Host\n",
      "    2446         -         -         -           -   1.759953s  Gpu page fault groups\n",
      "Total CPU Page faults: 6144\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_max2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d76b07b-4fad-4010-8228-52ca89770c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Device-side CUDA Event completion trace is currently enabled.\n",
      "         This may increase runtime overhead and the likelihood of false\n",
      "         dependencies across CUDA Streams. If you wish to avoid this, please\n",
      "         disable the feature with --cuda-event-trace=false.\n",
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = MAX\n",
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Error count (CUDA program): 0\n",
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-6789.qdstrm'\n",
      "[1/1] [========================100%] CUDA_max2.nsys-rep\n",
      "Generated:\n",
      "\t/home/jupyter-lorenz_marqueses@d-08e53/CUDA_max2.nsys-rep\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nsys profile  -o CUDA_max2 ./CUDA_max2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cde268-f9d9-4464-a996-61d9370bca74",
   "metadata": {
    "id": "L-V-aZxHQMbH"
   },
   "source": [
    "## Grid-stride CUDA (prefetch + page creation)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "062cb52c-2346-4b2d-8e41-b4533bca6282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_max3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_max3.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define MIN_VAL -20\n",
    "#define MAX_VAL 20\n",
    "\n",
    "__global__\n",
    "void cuda_max(size_t n, float *max_arr, float *A, float *B, int *idx) {\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride) {\n",
    "        max_arr[i] = (A[i] > B[i]) ? A[i] : B[i];\n",
    "        idx[i] = (A[i] >= B[i]) ? 0 : 1;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const size_t ARRAY_SIZE = 1 << 28;\n",
    "    const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    "    \n",
    "    // Execute 30 times\n",
    "    const size_t loope = 30;\n",
    "    \n",
    "    // Declare array\n",
    "    float *A, *B, *max_arr;\n",
    "    int *idx;\n",
    "    cudaMallocManaged(&A, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&B, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&max_arr, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&idx, ARRAY_BYTES);\n",
    "\n",
    "    // Get gpu id\n",
    "    int device = -1;\n",
    "    cudaGetDevice(&device);\n",
    "    //\"prefetch data\" to create CPU page memory\n",
    "    // TODO: Tama ba to can u check\n",
    "    cudaMemPrefetchAsync(A, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "    cudaMemPrefetchAsync(B, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "    //\"prefetch data\" to create GPU page memory\n",
    "    cudaMemPrefetchAsync(max_arr, ARRAY_BYTES, device, NULL);\n",
    "    cudaMemPrefetchAsync(idx, ARRAY_BYTES, device, NULL);\n",
    "\n",
    "    // *** init array\n",
    "    for (size_t i = 0; i < ARRAY_SIZE; i++) {\n",
    "        A[i] =\n",
    "            MIN_VAL + ((float)rand() / (float)RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "        B[i] =\n",
    "            MIN_VAL + ((float)rand() / (float)RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "    }\n",
    "\n",
    "    // Prefetch\n",
    "    cudaMemPrefetchAsync(A, ARRAY_BYTES, device, NULL);\n",
    "    cudaMemPrefetchAsync(B, ARRAY_BYTES, device, NULL);\n",
    "    // *** setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads - 1) / numThreads;\n",
    "    printf(\"*** function = MAX\\n\");\n",
    "    printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "    printf(\"numBlocks = %lu, numThreads = %lu \\n\", numBlocks, numThreads);\n",
    "    for (size_t i = 0; i < loope; i++)\n",
    "        cuda_max<<<numBlocks, numThreads>>>(ARRAY_SIZE, max_arr, A, B, idx);\n",
    "    // barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    cudaMemPrefetchAsync(max_arr, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "    cudaMemPrefetchAsync(A, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "    cudaMemPrefetchAsync(B, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "    cudaMemPrefetchAsync(idx, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "\n",
    "    // error checking\n",
    "    size_t err_count = 0;\n",
    "    for (size_t i = 0; i < ARRAY_SIZE; i++) {\n",
    "        if (((A[i] > B[i]) ? A[i] : B[i]) != max_arr[i]) err_count++;\n",
    "    }\n",
    "    printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "    // free memory\n",
    "    cudaFree(A);\n",
    "    cudaFree(B);\n",
    "    cudaFree(max_arr);\n",
    "    cudaFree(idx);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb32adfe-6731-49d1-bcce-6fad3bf98f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_max3.cu -o CUDA_max3 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3600e71-8691-4d70-b77e-6d5d823126c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1064669== NVPROF is profiling process 1064669, command: ./CUDA_max3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = MAX\n",
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1064669== Profiling application: ./CUDA_max3\n",
      "==1064669== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  641.54ms        30  21.385ms  20.674ms  26.005ms  cuda_max(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   62.39%  5.97806s        10  597.81ms  5.1522ms  1.55978s  cudaMemPrefetchAsync\n",
      "                   24.59%  2.35606s         4  589.01ms  308.77us  2.35324s  cudaMallocManaged\n",
      "                    6.72%  644.32ms         1  644.32ms  644.32ms  644.32ms  cudaDeviceSynchronize\n",
      "                    3.44%  329.32ms         4  82.331ms  75.808ms  86.327ms  cudaFree\n",
      "                    2.84%  272.14ms        30  9.0712ms  7.7460us  271.59ms  cudaLaunchKernel\n",
      "                    0.01%  1.2830ms       114  11.254us     127ns  435.49us  cuDeviceGetAttribute\n",
      "                    0.00%  339.77us         1  339.77us  339.77us  339.77us  cuDeviceGetName\n",
      "                    0.00%  151.96us         1  151.96us  151.96us  151.96us  cudaGetDevice\n",
      "                    0.00%  94.080us         1  94.080us  94.080us  94.080us  cuDeviceTotalMem\n",
      "                    0.00%  21.414us         1  21.414us  21.414us  21.414us  cuDeviceGetPCIBusId\n",
      "                    0.00%  13.307us         3  4.4350us     226ns  8.0640us  cuDeviceGetCount\n",
      "                    0.00%  11.411us         2  5.7050us  2.8880us  8.5230us  cuDeviceGet\n",
      "                    0.00%  6.7500us         1  6.7500us  6.7500us  6.7500us  cuModuleGetLoadingMode\n",
      "                    0.00%     544ns         1     544ns     544ns     544ns  cuDeviceGetUuid\n",
      "\n",
      "==1064669== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "    1024  2.0000MB  2.0000MB  2.0000MB  2.000000GB  390.0729ms  Host To Device\n",
      "    2048  2.0000MB  2.0000MB  2.0000MB  4.000000GB   2.778546s  Device To Host\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_max3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6422e1d2-5607-4ea3-ba0b-03fbf0537c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Device-side CUDA Event completion trace is currently enabled.\n",
      "         This may increase runtime overhead and the likelihood of false\n",
      "         dependencies across CUDA Streams. If you wish to avoid this, please\n",
      "         disable the feature with --cuda-event-trace=false.\n",
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = MAX\n",
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n",
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-7cdc.qdstrm'\n",
      "[1/1] [========================100%] CUDA_max3.nsys-rep\n",
      "Generated:\n",
      "\t/home/jupyter-lorenz_marqueses@d-08e53/CUDA_max3.nsys-rep\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nsys profile  -o CUDA_max3 ./CUDA_max3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d40b9c-7f0b-4f77-ad62-c8fe05d5747b",
   "metadata": {
    "id": "L-V-aZxHQMbH"
   },
   "source": [
    "## Grid-stride CUDA (prefetching + page creation + mem advise)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ac6b02c-331c-4728-b4c5-6cac63fceb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_max4.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_max4.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define MIN_VAL -20\n",
    "#define MAX_VAL 20\n",
    "\n",
    "__global__\n",
    "void cuda_max(size_t n, float *max_arr, float *A, float *B, int *idx) {\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride) {\n",
    "        max_arr[i] = (A[i] > B[i]) ? A[i] : B[i];\n",
    "        idx[i] = (A[i] >= B[i]) ? 0 : 1;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const size_t ARRAY_SIZE = 1 << 28;\n",
    "    const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    "    // number of times the program is to be executed\n",
    "    const size_t loope = 30;\n",
    "    // declare array\n",
    "    float *A, *B, *max_arr;\n",
    "    int *idx;\n",
    "    cudaMallocManaged(&A, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&B, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&max_arr, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&idx, ARRAY_BYTES);\n",
    "\n",
    "    // get gpu id\n",
    "    int device = -1;\n",
    "    cudaGetDevice(&device);\n",
    "    // mem advise\n",
    "    cudaMemAdvise(A, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation,\n",
    "                  cudaCpuDeviceId);\n",
    "    cudaMemAdvise(A, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "    cudaMemAdvise(B, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation,\n",
    "                  cudaCpuDeviceId);\n",
    "    cudaMemAdvise(B, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "\n",
    "    //\"prefetch data\" to create CPU page memory\n",
    "    // TODO: See previous cell\n",
    "    cudaMemPrefetchAsync(A, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "    cudaMemPrefetchAsync(B, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "    //\"prefetch data\" to create GPU page memory\n",
    "    cudaMemPrefetchAsync(max_arr, ARRAY_BYTES, device, NULL);\n",
    "    cudaMemPrefetchAsync(idx, ARRAY_BYTES, device, NULL);\n",
    "\n",
    "    // *** init array\n",
    "    for (size_t i = 0; i < ARRAY_SIZE; i++) {\n",
    "        A[i] =\n",
    "            MIN_VAL + ((float)rand() / (float)RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "        B[i] =\n",
    "            MIN_VAL + ((float)rand() / (float)RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "    }\n",
    "\n",
    "    cudaMemPrefetchAsync(A, ARRAY_BYTES, device, NULL);\n",
    "    cudaMemPrefetchAsync(B, ARRAY_BYTES, device, NULL);\n",
    "\n",
    "    // *** setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads - 1) / numThreads;\n",
    "    printf(\"*** function = MAX\\n\");\n",
    "    printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "    printf(\"numBlocks = %lu, numThreads = %lu \\n\", numBlocks, numThreads);\n",
    "    for (size_t i = 0; i < loope; i++)\n",
    "        cuda_max<<<numBlocks, numThreads>>>(ARRAY_SIZE, max_arr, A, B, idx);\n",
    "    // barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    cudaMemPrefetchAsync(max_arr, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "    cudaMemPrefetchAsync(A, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "    cudaMemPrefetchAsync(B, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "    cudaMemPrefetchAsync(idx, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "\n",
    "    // error checking\n",
    "    size_t err_count = 0;\n",
    "    for (size_t i = 0; i < ARRAY_SIZE; i++) {\n",
    "        if (((A[i] > B[i]) ? A[i] : B[i]) != max_arr[i]) err_count++;\n",
    "    }\n",
    "    printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "    // free memory\n",
    "    cudaFree(A);\n",
    "    cudaFree(B);\n",
    "    cudaFree(max_arr);\n",
    "    cudaFree(idx);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20fa3e72-1200-40c6-ac89-978d72a48d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_max4.cu -o CUDA_max4 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f6dae19-cab5-4453-b414-598749ddb1c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1064832== NVPROF is profiling process 1064832, command: ./CUDA_max4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = MAX\n",
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1064832== Profiling application: ./CUDA_max4\n",
      "==1064832== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  634.00ms        30  21.133ms  15.910ms  26.025ms  cuda_max(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   56.98%  4.23570s        10  423.57ms  5.9735ms  1.15317s  cudaMemPrefetchAsync\n",
      "                   28.50%  2.11811s         4  529.53ms  225.45us  2.11498s  cudaMallocManaged\n",
      "                    8.57%  637.17ms         1  637.17ms  637.17ms  637.17ms  cudaDeviceSynchronize\n",
      "                    5.82%  432.88ms         4  108.22ms  82.158ms  118.31ms  cudaFree\n",
      "                    0.10%  7.3727ms        30  245.76us  9.5710us  6.7414ms  cudaLaunchKernel\n",
      "                    0.01%  792.26us       114  6.9490us     108ns  328.18us  cuDeviceGetAttribute\n",
      "                    0.01%  588.26us         4  147.07us  9.9940us  478.61us  cudaMemAdvise\n",
      "                    0.00%  207.10us         1  207.10us  207.10us  207.10us  cuDeviceGetName\n",
      "                    0.00%  176.22us         1  176.22us  176.22us  176.22us  cudaGetDevice\n",
      "                    0.00%  40.671us         1  40.671us  40.671us  40.671us  cuDeviceTotalMem\n",
      "                    0.00%  16.185us         1  16.185us  16.185us  16.185us  cuDeviceGetPCIBusId\n",
      "                    0.00%  15.546us         2  7.7730us     175ns  15.371us  cuDeviceGet\n",
      "                    0.00%  9.7180us         3  3.2390us     128ns  8.9630us  cuDeviceGetCount\n",
      "                    0.00%     527ns         1     527ns     527ns     527ns  cuModuleGetLoadingMode\n",
      "                    0.00%     203ns         1     203ns     203ns     203ns  cuDeviceGetUuid\n",
      "\n",
      "==1064832== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "    1024  2.0000MB  2.0000MB  2.0000MB  2.000000GB  311.3283ms  Host To Device\n",
      "    1024  2.0000MB  2.0000MB  2.0000MB  2.000000GB   1.486321s  Device To Host\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_max4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea576d1a-8951-46f0-a878-f9b01687e695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Device-side CUDA Event completion trace is currently enabled.\n",
      "         This may increase runtime overhead and the likelihood of false\n",
      "         dependencies across CUDA Streams. If you wish to avoid this, please\n",
      "         disable the feature with --cuda-event-trace=false.\n",
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = MAX\n",
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to create '/home/jupyter-lorenz_marqueses@d-08e53/CUDA_max4.nsys-rep': File exists.\n",
      "Use `--force-overwrite true` to overwrite existing files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-ce98.qdstrm'\n",
      "[1/1] [========================100%] nsys-report-dca0.nsys-rep\n",
      "Generated:\n",
      "\t/tmp/nsys-report-dca0.nsys-rep\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nsys profile  -o CUDA_max4 ./CUDA_max4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9959c-555e-4df3-9554-12446b665e59",
   "metadata": {},
   "source": [
    "## CUDA Classic MEMCPY\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2f8f8b0-f272-441d-99af-9a101e258ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_max5.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_max5.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define MIN_VAL -20\n",
    "#define MAX_VAL 20\n",
    "\n",
    "__global__\n",
    "void cuda_max(size_t n, float *max_arr, float *A, float *B, int *idx) {\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride) {\n",
    "        max_arr[i] = (A[i] > B[i]) ? A[i] : B[i];\n",
    "        idx[i] = (A[i] >= B[i]) ? 0 : 1;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const size_t ARRAY_SIZE = 1 << 28;\n",
    "    const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    "    // number of times the program is to be executed\n",
    "    const size_t loope = 30;\n",
    "    // declare array\n",
    "    float *A_host, *B_host, *max_arr_host;\n",
    "    float *A_device, *B_device, *max_arr_device;\n",
    "    int *idx_host, *idx_device;\n",
    "\n",
    "    // get gpu id\n",
    "    int device = -1;\n",
    "    cudaGetDevice(&device);\n",
    "\n",
    "    // malloc host\n",
    "    A_host = (float*)malloc(ARRAY_BYTES);\n",
    "    B_host = (float*)malloc(ARRAY_BYTES);\n",
    "    max_arr_host = (float*)malloc(ARRAY_BYTES);\n",
    "    idx_host = (int*)malloc(ARRAY_BYTES);\n",
    "\n",
    "    // malloc device\n",
    "    cudaMalloc((void**)&A_device, ARRAY_BYTES);\n",
    "    cudaMalloc((void**)&B_device, ARRAY_BYTES);\n",
    "    cudaMalloc((void**)&max_arr_device, ARRAY_BYTES);\n",
    "    cudaMalloc((void**)&idx_device, ARRAY_BYTES);\n",
    "    \n",
    "    // *** init array host\n",
    "    for (size_t i = 0; i < ARRAY_SIZE; i++) {\n",
    "        A_host[i] =\n",
    "            MIN_VAL + ((float)rand() / (float)RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "        B_host[i] =\n",
    "            MIN_VAL + ((float)rand() / (float)RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "    }\n",
    "\n",
    "    cudaMemcpy(A_device, A_host, ARRAY_BYTES, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(B_device, B_host, ARRAY_BYTES, cudaMemcpyHostToDevice);\n",
    "\n",
    "\n",
    "    // *** setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads - 1) / numThreads;\n",
    "    printf(\"*** function = MAX\\n\");\n",
    "    printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "    printf(\"numBlocks = %lu, numThreads = %lu \\n\", numBlocks, numThreads);\n",
    "    for (size_t i = 0; i < loope; i++)\n",
    "        cuda_max<<<numBlocks, numThreads>>>(ARRAY_SIZE, max_arr_device, A_device, B_device, idx_device);\n",
    "    // barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    cudaMemcpy(max_arr_host, max_arr_device, ARRAY_BYTES, cudaMemcpyDeviceToHost);\n",
    "    cudaMemcpy(idx_host, idx_device, ARRAY_BYTES, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // error checking\n",
    "    size_t err_count = 0;\n",
    "    for (size_t i = 0; i < ARRAY_SIZE; i++) {\n",
    "        if (((A_host[i] > B_host[i]) ? A_host[i] : B_host[i]) != max_arr_host[i]) err_count++;\n",
    "    }\n",
    "    printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "    // free memory\n",
    "    cudaFree(A_device);\n",
    "    cudaFree(B_device);\n",
    "    cudaFree(max_arr_device);\n",
    "    cudaFree(idx_device);\n",
    "\n",
    "    free(A_host);\n",
    "    free(B_host);\n",
    "    free(max_arr_host);\n",
    "    free(idx_host);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0364cd1-0402-4b04-b0a2-2ba830c2a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_max5.cu -o CUDA_max5 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fb0ba20-5ea5-4d70-868b-ce0f446ade09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1065000== NVPROF is profiling process 1065000, command: ./CUDA_max5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = MAX\n",
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1065000== Profiling application: ./CUDA_max5\n",
      "==1065000== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   77.38%  11.9239s         2  5.96193s  5.55298s  6.37088s  [CUDA memcpy DtoH]\n",
      "                   18.60%  2.86563s         2  1.43282s  1.15426s  1.71138s  [CUDA memcpy HtoD]\n",
      "                    4.02%  619.47ms        30  20.649ms  15.669ms  26.049ms  cuda_max(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   83.21%  14.8179s         4  3.70447s  1.15568s  6.38560s  cudaMemcpy\n",
      "                   13.16%  2.34363s         4  585.91ms  296.60us  2.34187s  cudaMalloc\n",
      "                    3.50%  622.47ms         1  622.47ms  622.47ms  622.47ms  cudaDeviceSynchronize\n",
      "                    0.08%  14.677ms         4  3.6692ms  3.2173ms  4.0574ms  cudaFree\n",
      "                    0.04%  6.3394ms        30  211.31us  10.684us  5.6986ms  cudaLaunchKernel\n",
      "                    0.01%  1.1532ms       114  10.115us     154ns  437.78us  cuDeviceGetAttribute\n",
      "                    0.01%  895.38us         1  895.38us  895.38us  895.38us  cudaGetDevice\n",
      "                    0.00%  571.96us         1  571.96us  571.96us  571.96us  cuDeviceGetName\n",
      "                    0.00%  62.966us         1  62.966us  62.966us  62.966us  cuDeviceTotalMem\n",
      "                    0.00%  41.620us         1  41.620us  41.620us  41.620us  cuDeviceGetPCIBusId\n",
      "                    0.00%  12.130us         2  6.0650us  3.1780us  8.9520us  cuDeviceGet\n",
      "                    0.00%  7.9630us         3  2.6540us     429ns  3.8650us  cuDeviceGetCount\n",
      "                    0.00%  2.0430us         1  2.0430us  2.0430us  2.0430us  cuDeviceGetUuid\n",
      "                    0.00%  1.6480us         1  1.6480us  1.6480us  1.6480us  cuModuleGetLoadingMode\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_max5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0aca0c37-4605-493f-b514-6608418e9a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Device-side CUDA Event completion trace is currently enabled.\n",
      "         This may increase runtime overhead and the likelihood of false\n",
      "         dependencies across CUDA Streams. If you wish to avoid this, please\n",
      "         disable the feature with --cuda-event-trace=false.\n",
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = MAX\n",
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n",
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-34ed.qdstrm'\n",
      "[1/1] [========================100%] CUDA_max5.nsys-rep\n",
      "Generated:\n",
      "\t/home/jupyter-lorenz_marqueses@d-08e53/CUDA_max5.nsys-rep\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nsys profile  -o CUDA_max5 ./CUDA_max5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6c11cd-4519-41b0-a08d-e234c522d11c",
   "metadata": {},
   "source": [
    "## CUDA data init in a CUDA kernel\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b511d5d-ccdf-4b68-bdd8-9d4150a06e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_max_init.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_max_init.cu\n",
    "#include<stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <curand_kernel.h>\n",
    "\n",
    "#define MIN_VAL -20\n",
    "#define MAX_VAL 20\n",
    "\n",
    "__global__\n",
    "void cuda_max(size_t n, float* max_arr, float* A, float* B, int* idx) {\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride) {\n",
    "        max_arr[i] = (A[i] > B[i]) ? A[i] : B[i];\n",
    "        idx[i] = (A[i] >= B[i]) ? 0 : 1;\n",
    "    }\n",
    "}\n",
    "\n",
    "// For the purposes of testing we use i*2 and i for the initialized elements\n",
    "// Shouldn't impact the performance measurement as they are still stored as FP\n",
    "__global__\n",
    "void initialize(size_t n, float* A, float* B) {\n",
    "    // Init array\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (size_t i = index; i < n; i+= stride) {\n",
    "        A[i] =\n",
    "            i * 2;\n",
    "        B[i] =\n",
    "            i;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const size_t ARRAY_SIZE = 1 << 28;\n",
    "    const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    "    \n",
    "    // Execute 30 times\n",
    "    const size_t loope = 30;\n",
    "    \n",
    "    // Declare arrays\n",
    "    float *A, *B, *max_arr;\n",
    "    int* idx;\n",
    "\n",
    "    cudaMallocManaged(&A, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&B, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&max_arr, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&idx, ARRAY_BYTES);\n",
    "    \n",
    "    // Setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads - 1) / numThreads;\n",
    "    \n",
    "    printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "    printf(\"numBlocks = %lu, numThreads = %lu \\n\", numBlocks, numThreads);\n",
    "\n",
    "    // Execute kernel\n",
    "    initialize<<<numBlocks, numThreads>>>(ARRAY_SIZE, A, B);\n",
    "    for (size_t i = 0; i < loope; i++)\n",
    "        cuda_max<<<numBlocks, numThreads>>>(ARRAY_SIZE, max_arr, A, B, idx);\n",
    "    \n",
    "    // Barrier\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Error checking\n",
    "    size_t err_count = 0;\n",
    "    for (size_t i = 0; i < ARRAY_SIZE; i++) {\n",
    "        if (((A[i] > B[i]) ? A[i] : B[i]) != max_arr[i]) err_count++;\n",
    "    }\n",
    "    printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "    \n",
    "    // Free memory\n",
    "    cudaFree(A);\n",
    "    cudaFree(B);\n",
    "    cudaFree(max_arr);\n",
    "    cudaFree(idx);\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "553a874e-8e51-430c-9d05-dd497d9eeab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_max_init.cu -o CUDA_max_init -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b07463f0-ad60-4aa2-95df-4ece6384c683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1065191== NVPROF is profiling process 1065191, command: ./CUDA_max_init\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1065191== Profiling application: ./CUDA_max_init\n",
      "==1065191== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   52.70%  745.52ms        30  24.851ms  5.4707ms  586.77ms  cuda_max(unsigned long, float*, float*, float*, int*)\n",
      "                   47.30%  669.06ms         1  669.06ms  669.06ms  669.06ms  initialize(unsigned long, float*, float*)\n",
      "      API calls:   52.54%  1.98188s         4  495.47ms  132.97us  1.98047s  cudaMallocManaged\n",
      "                   37.49%  1.41407s         1  1.41407s  1.41407s  1.41407s  cudaDeviceSynchronize\n",
      "                    9.30%  350.99ms         4  87.747ms  27.533ms  115.60ms  cudaFree\n",
      "                    0.65%  24.487ms        31  789.91us  8.7370us  23.895ms  cudaLaunchKernel\n",
      "                    0.02%  648.09us       114  5.6850us     135ns  231.90us  cuDeviceGetAttribute\n",
      "                    0.00%  152.43us         1  152.43us  152.43us  152.43us  cuDeviceGetName\n",
      "                    0.00%  22.498us         1  22.498us  22.498us  22.498us  cuDeviceTotalMem\n",
      "                    0.00%  16.971us         1  16.971us  16.971us  16.971us  cuDeviceGetPCIBusId\n",
      "                    0.00%  6.3480us         2  3.1740us     411ns  5.9370us  cuDeviceGet\n",
      "                    0.00%  6.1390us         3  2.0460us     392ns  4.5420us  cuDeviceGetCount\n",
      "                    0.00%  2.5900us         1  2.5900us  2.5900us  2.5900us  cuModuleGetLoadingMode\n",
      "                    0.00%  1.4510us         1  1.4510us  1.4510us  1.4510us  cuDeviceGetUuid\n",
      "\n",
      "==1065191== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "   18432  170.67KB  4.0000KB  0.9961MB  3.000000GB   1.374677s  Device To Host\n",
      "    4090         -         -         -           -   1.249830s  Gpu page fault groups\n",
      "Total CPU Page faults: 9216\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_max_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6ac494b-5ee5-4614-af72-b30973387701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Device-side CUDA Event completion trace is currently enabled.\n",
      "         This may increase runtime overhead and the likelihood of false\n",
      "         dependencies across CUDA Streams. If you wish to avoid this, please\n",
      "         disable the feature with --cuda-event-trace=false.\n",
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n",
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-e6a6.qdstrm'\n",
      "[1/1] [========================100%] CUDA_max_init.nsys-rep\n",
      "Generated:\n",
      "\t/home/jupyter-lorenz_marqueses@d-08e53/CUDA_max_init.nsys-rep\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nsys profile  -o CUDA_max_init ./CUDA_max_init"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
