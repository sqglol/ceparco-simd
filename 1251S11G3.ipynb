{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d18cbde8-c4fc-44c0-bee5-413756f359e9",
   "metadata": {
    "id": "L-V-aZxHQMbH"
   },
   "source": [
    "# CUDA (Grid-Stride Loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b98666f2-56a7-4c01-aeb3-0d9fd785de73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/bin:/bin:/usr/bin:/usr/local/cuda/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add the directory containing the executable to the PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/cuda/bin\"\n",
    "\n",
    "# Check if the directory is added to the PATH\n",
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea1ad124-533c-40bc-9093-6d4f6306bd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_max.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_max.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define MIN_VAL -20\n",
    "#define MAX_VAL 20\n",
    "\n",
    "__global__\n",
    "void cuda_max(size_t n, float* max_arr, float *A, float *B, int* idx){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride){\n",
    "        max_arr[i] = (A[i] > B[i]) ? A[i] : B[i];\n",
    "        idx[i] = (A[i] >= B[i]) ? 0 : 1;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 1;\n",
    "//declare array\n",
    "  float *A, *B, *max_arr;\n",
    "  int *idx;\n",
    "\n",
    "  cudaMallocManaged(&A, ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, ARRAY_BYTES);\n",
    "  cudaMallocManaged(&max_arr, ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, ARRAY_BYTES);\n",
    "// *** init array\n",
    "  for (size_t i=0; i<ARRAY_SIZE; i++){\n",
    "     A[i] = MIN_VAL + ((float) rand() / (float) RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "     B[i] = MIN_VAL + ((float) rand() / (float) RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "  }\n",
    "// *** setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "  printf(\"*** function = DAXPY\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    cuda_max <<<numBlocks, numThreads>>> (ARRAY_SIZE,max_arr,A,B, idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "//error checking\n",
    "  size_t err_count = 0;\n",
    "  for (size_t i=0; i<ARRAY_SIZE; i++){\n",
    "    if(((A[i] > B[i]) ? A[i] : B[i]) != max_arr[i])\n",
    "      err_count++;\n",
    "  }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(max_arr);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a26f1e39-390a-4007-9684-439792e30803",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_max.cu -o CUDA_max -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5d14f22-634d-4d55-988c-4028232e37c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==892676== NVPROF is profiling process 892676, command: ./CUDA_max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = DAXPY\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==892676== Profiling application: ./CUDA_max\n",
      "==892676== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  101.38ms         1  101.38ms  101.38ms  101.38ms  cuda_max(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   85.69%  1.01271s         4  253.18ms  44.573us  1.01212s  cudaMallocManaged\n",
      "                    8.58%  101.40ms         1  101.40ms  101.40ms  101.40ms  cudaDeviceSynchronize\n",
      "                    3.70%  43.734ms         1  43.734ms  43.734ms  43.734ms  cudaLaunchKernel\n",
      "                    1.95%  23.052ms         3  7.6842ms  6.3322ms  10.112ms  cudaFree\n",
      "                    0.06%  678.59us       114  5.9520us     190ns  270.28us  cuDeviceGetAttribute\n",
      "                    0.02%  191.96us         1  191.96us  191.96us  191.96us  cuDeviceGetName\n",
      "                    0.00%  53.679us         1  53.679us  53.679us  53.679us  cuDeviceTotalMem\n",
      "                    0.00%  21.673us         1  21.673us  21.673us  21.673us  cuDeviceGetPCIBusId\n",
      "                    0.00%  10.187us         3  3.3950us     254ns  9.0330us  cuDeviceGetCount\n",
      "                    0.00%  5.7200us         2  2.8600us     399ns  5.3210us  cuDeviceGet\n",
      "                    0.00%  1.3390us         1  1.3390us  1.3390us  1.3390us  cuModuleGetLoadingMode\n",
      "                    0.00%     493ns         1     493ns     493ns     493ns  cuDeviceGetUuid\n",
      "\n",
      "==892676== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "    3937  27.050KB  4.0000KB  0.9922MB  104.0000MB  29.38513ms  Host To Device\n",
      "    1146  171.39KB  4.0000KB  0.9961MB  191.8125MB  51.32815ms  Device To Host\n",
      "Total CPU Page faults: 957\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77346d78-718c-4c27-9a67-b07653505dde",
   "metadata": {
    "id": "L-V-aZxHQMbH"
   },
   "source": [
    "# CUDA (Grid-Stride Loop + Prefetching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bafd92a-91eb-41b0-9ead-4876446bdbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_max2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_max2.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define MIN_VAL -20\n",
    "#define MAX_VAL 20\n",
    "\n",
    "__global__\n",
    "void cuda_max(size_t n, float* max_arr, float *A, float *B, int* idx){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride){\n",
    "        max_arr[i] = (A[i] > B[i]) ? A[i] : B[i];\n",
    "        idx[i] = (A[i] >= B[i]) ? 0 : 1;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 1;\n",
    "//declare array\n",
    "  float *A, *B, *max_arr;\n",
    "  int *idx;\n",
    "\n",
    "  cudaMallocManaged(&A, ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, ARRAY_BYTES);\n",
    "  cudaMallocManaged(&max_arr, ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, ARRAY_BYTES);\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "// *** init array\n",
    "  for (size_t i=0; i<ARRAY_SIZE; i++){\n",
    "     A[i] = MIN_VAL + ((float) rand() / (float) RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "     B[i] = MIN_VAL + ((float) rand() / (float) RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "  }\n",
    "cudaMemPrefetchAsync(A,ARRAY_BYTES,device,NULL);\n",
    "cudaMemPrefetchAsync(B,ARRAY_BYTES,device,NULL);\n",
    "// *** setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "  printf(\"*** function = MAX\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    cuda_max <<<numBlocks, numThreads>>> (ARRAY_SIZE,max_arr,A,B, idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "  cudaMemPrefetchAsync(max_arr,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "//error checking\n",
    "  size_t err_count = 0;\n",
    "  for (size_t i=0; i<ARRAY_SIZE; i++){\n",
    "    if(((A[i] > B[i]) ? A[i] : B[i]) != max_arr[i])\n",
    "      err_count++;\n",
    "  }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(max_arr);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26130961-703f-42e1-82df-d314a47f5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_max2.cu -o CUDA_max2 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e99f4c2-fa30-4e85-afa7-e41addf513c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==894344== NVPROF is profiling process 894344, command: ./CUDA_max2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = DAXPY\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==894344== Profiling application: ./CUDA_max2\n",
      "==894344== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  35.988ms         1  35.988ms  35.988ms  35.988ms  cuda_max(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   82.48%  1.32440s         4  331.10ms  73.951us  1.32353s  cudaMallocManaged\n",
      "                   14.14%  227.07ms         6  37.845ms  9.8566ms  80.074ms  cudaMemPrefetchAsync\n",
      "                    2.25%  36.058ms         1  36.058ms  36.058ms  36.058ms  cudaDeviceSynchronize\n",
      "                    0.93%  14.939ms         4  3.7348ms  3.1393ms  4.1942ms  cudaFree\n",
      "                    0.15%  2.3542ms         1  2.3542ms  2.3542ms  2.3542ms  cudaLaunchKernel\n",
      "                    0.03%  549.31us       114  4.8180us     143ns  203.00us  cuDeviceGetAttribute\n",
      "                    0.02%  296.27us         1  296.27us  296.27us  296.27us  cuDeviceGetName\n",
      "                    0.00%  28.586us         1  28.586us  28.586us  28.586us  cuDeviceTotalMem\n",
      "                    0.00%  25.153us         1  25.153us  25.153us  25.153us  cuDeviceGetPCIBusId\n",
      "                    0.00%  21.107us         1  21.107us  21.107us  21.107us  cudaGetDevice\n",
      "                    0.00%  9.3830us         3  3.1270us     191ns  7.9760us  cuDeviceGetCount\n",
      "                    0.00%  5.8440us         2  2.9220us     748ns  5.0960us  cuDeviceGet\n",
      "                    0.00%     629ns         1     629ns     629ns     629ns  cuModuleGetLoadingMode\n",
      "                    0.00%     310ns         1     310ns     310ns     310ns  cuDeviceGetUuid\n",
      "\n",
      "==894344== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  16.55234ms  Host To Device\n",
      "     128  2.0000MB  2.0000MB  2.0000MB  256.0000MB  71.48372ms  Device To Host\n",
      "     154         -         -         -           -  35.74180ms  Gpu page fault groups\n",
      "Total CPU Page faults: 384\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_max2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cde268-f9d9-4464-a996-61d9370bca74",
   "metadata": {
    "id": "L-V-aZxHQMbH"
   },
   "source": [
    "# CUDA (Grid-Stride Loop + Prefetching + Page Creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "062cb52c-2346-4b2d-8e41-b4533bca6282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_max3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_max3.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define MIN_VAL -20\n",
    "#define MAX_VAL 20\n",
    "\n",
    "__global__\n",
    "void cuda_max(size_t n, float* max_arr, float *A, float *B, int* idx){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride){\n",
    "        max_arr[i] = (A[i] > B[i]) ? A[i] : B[i];\n",
    "        idx[i] = (A[i] >= B[i]) ? 0 : 1;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 1;\n",
    "//declare array\n",
    "  float *A, *B, *max_arr;\n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, ARRAY_BYTES);\n",
    "  cudaMallocManaged(&max_arr, ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "//\"prefetch data\" to create CPU page memory\n",
    "  cudaMemPrefetchAsync(A,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "//\"prefetch data\" to create GPU page memory\n",
    "  cudaMemPrefetchAsync(max_arr,ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// *** init array\n",
    "  for (size_t i=0; i<ARRAY_SIZE; i++){\n",
    "     A[i] = MIN_VAL + ((float) rand() / (float) RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "     B[i] = MIN_VAL + ((float) rand() / (float) RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "  }\n",
    "\n",
    "cudaMemPrefetchAsync(A,ARRAY_BYTES,device,NULL);\n",
    "cudaMemPrefetchAsync(B,ARRAY_BYTES,device,NULL);\n",
    "// *** setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "  printf(\"*** function = MAX\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    cuda_max <<<numBlocks, numThreads>>> (ARRAY_SIZE,max_arr,A,B, idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "  cudaMemPrefetchAsync(max_arr,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "//error checking\n",
    "  size_t err_count = 0;\n",
    "  for (size_t i=0; i<ARRAY_SIZE; i++){\n",
    "    if(((A[i] > B[i]) ? A[i] : B[i]) != max_arr[i])\n",
    "      err_count++;\n",
    "  }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(max_arr);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb32adfe-6731-49d1-bcce-6fad3bf98f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_max3.cu -o CUDA_max3 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3600e71-8691-4d70-b77e-6d5d823126c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==896838== NVPROF is profiling process 896838, command: ./CUDA_max3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = MAX\n",
      "numElements = 1024\n",
      "numBlocks = 1, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==896838== Profiling application: ./CUDA_max3\n",
      "==896838== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.4880us         1  3.4880us  3.4880us  3.4880us  cuda_max(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   99.37%  882.08ms         4  220.52ms  6.0900us  881.89ms  cudaMallocManaged\n",
      "                    0.34%  3.0067ms        10  300.67us  39.198us  1.9071ms  cudaMemPrefetchAsync\n",
      "                    0.12%  1.0534ms         1  1.0534ms  1.0534ms  1.0534ms  cudaLaunchKernel\n",
      "                    0.07%  647.45us       114  5.6790us     141ns  273.18us  cuDeviceGetAttribute\n",
      "                    0.07%  621.94us         4  155.48us  27.865us  472.47us  cudaFree\n",
      "                    0.02%  178.47us         1  178.47us  178.47us  178.47us  cuDeviceGetName\n",
      "                    0.00%  28.086us         1  28.086us  28.086us  28.086us  cuDeviceTotalMem\n",
      "                    0.00%  17.132us         1  17.132us  17.132us  17.132us  cudaDeviceSynchronize\n",
      "                    0.00%  13.778us         1  13.778us  13.778us  13.778us  cuDeviceGetPCIBusId\n",
      "                    0.00%  9.6080us         1  9.6080us  9.6080us  9.6080us  cudaGetDevice\n",
      "                    0.00%  6.6280us         3  2.2090us     229ns  4.0660us  cuDeviceGetCount\n",
      "                    0.00%  5.4510us         2  2.7250us     341ns  5.1100us  cuDeviceGet\n",
      "                    0.00%  1.6830us         1  1.6830us  1.6830us  1.6830us  cuDeviceGetUuid\n",
      "                    0.00%     380ns         1     380ns     380ns     380ns  cuModuleGetLoadingMode\n",
      "\n",
      "==896838== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "       2  4.0000KB  4.0000KB  4.0000KB  8.000000KB  7.327000us  Host To Device\n",
      "       4  4.0000KB  4.0000KB  4.0000KB  16.00000KB  6.783000us  Device To Host\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_max3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d40b9c-7f0b-4f77-ad62-c8fe05d5747b",
   "metadata": {
    "id": "L-V-aZxHQMbH"
   },
   "source": [
    "# CUDA (Grid-Stride Loop + Prefetching + Page Creation + Mem Advise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ac6b02c-331c-4728-b4c5-6cac63fceb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_max4.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_max4.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define MIN_VAL -20\n",
    "#define MAX_VAL 20\n",
    "\n",
    "__global__\n",
    "void cuda_max(size_t n, float* max_arr, float *A, float *B, int* idx){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride){\n",
    "        max_arr[i] = (A[i] > B[i]) ? A[i] : B[i];\n",
    "        idx[i] = (A[i] >= B[i]) ? 0 : 1;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 1;\n",
    "//declare array\n",
    "  float *A, *B, *max_arr;\n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, ARRAY_BYTES);\n",
    "  cudaMallocManaged(&max_arr, ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "//mem advise\n",
    "  cudaMemAdvise(A, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
    "  cudaMemAdvise(A, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "  cudaMemAdvise(B, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
    "  cudaMemAdvise(B, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "\n",
    "//\"prefetch data\" to create CPU page memory\n",
    "  cudaMemPrefetchAsync(A,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "//\"prefetch data\" to create GPU page memory\n",
    "  cudaMemPrefetchAsync(max_arr,ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// *** init array\n",
    "  for (size_t i=0; i<ARRAY_SIZE; i++){\n",
    "     A[i] = MIN_VAL + ((float) rand() / (float) RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "     B[i] = MIN_VAL + ((float) rand() / (float) RAND_MAX) * (MAX_VAL - MIN_VAL);\n",
    "  }\n",
    "\n",
    "cudaMemPrefetchAsync(A,ARRAY_BYTES,device,NULL);\n",
    "cudaMemPrefetchAsync(B,ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// *** setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "  printf(\"*** function = MAX\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    cuda_max <<<numBlocks, numThreads>>> (ARRAY_SIZE,max_arr,A,B, idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "  cudaMemPrefetchAsync(max_arr,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "//error checking\n",
    "  size_t err_count = 0;\n",
    "  for (size_t i=0; i<ARRAY_SIZE; i++){\n",
    "    if(((A[i] > B[i]) ? A[i] : B[i]) != max_arr[i])\n",
    "      err_count++;\n",
    "  }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(max_arr);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "20fa3e72-1200-40c6-ac89-978d72a48d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_max4.cu -o CUDA_max4 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f6dae19-cab5-4453-b414-598749ddb1c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==896892== NVPROF is profiling process 896892, command: ./CUDA_max4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = MAX\n",
      "numElements = 1024\n",
      "numBlocks = 1, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==896892== Profiling application: ./CUDA_max4\n",
      "==896892== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.8400us         1  3.8400us  3.8400us  3.8400us  cuda_max(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   99.63%  974.58ms         4  243.64ms  7.0280us  974.39ms  cudaMallocManaged\n",
      "                    0.13%  1.2510ms        10  125.10us  24.693us  332.57us  cudaMemPrefetchAsync\n",
      "                    0.09%  926.75us         1  926.75us  926.75us  926.75us  cudaLaunchKernel\n",
      "                    0.07%  676.74us         4  169.19us  28.727us  509.81us  cudaFree\n",
      "                    0.04%  427.46us       114  3.7490us     107ns  213.69us  cuDeviceGetAttribute\n",
      "                    0.02%  162.67us         4  40.666us  9.0430us  132.38us  cudaMemAdvise\n",
      "                    0.01%  127.09us         1  127.09us  127.09us  127.09us  cuDeviceGetName\n",
      "                    0.00%  26.263us         1  26.263us  26.263us  26.263us  cuDeviceTotalMem\n",
      "                    0.00%  13.047us         1  13.047us  13.047us  13.047us  cudaDeviceSynchronize\n",
      "                    0.00%  12.388us         3  4.1290us     122ns  11.993us  cuDeviceGetCount\n",
      "                    0.00%  9.3090us         1  9.3090us  9.3090us  9.3090us  cuDeviceGetPCIBusId\n",
      "                    0.00%  8.0810us         1  8.0810us  8.0810us  8.0810us  cudaGetDevice\n",
      "                    0.00%  2.6230us         2  1.3110us     163ns  2.4600us  cuDeviceGet\n",
      "                    0.00%     915ns         1     915ns     915ns     915ns  cuModuleGetLoadingMode\n",
      "                    0.00%     710ns         1     710ns     710ns     710ns  cuDeviceGetUuid\n",
      "\n",
      "==896892== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "       2  4.0000KB  4.0000KB  4.0000KB  8.000000KB  7.776000us  Host To Device\n",
      "       2  4.0000KB  4.0000KB  4.0000KB  8.000000KB  3.136000us  Device To Host\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_max4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea576d1a-8951-46f0-a878-f9b01687e695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Device-side CUDA Event completion trace is currently enabled.\n",
      "         This may increase runtime overhead and the likelihood of false\n",
      "         dependencies across CUDA Streams. If you wish to avoid this, please\n",
      "         disable the feature with --cuda-event-trace=false.\n",
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = DAXPY\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to create '/home/jupyter-benn_llovit@dlsu.e-0b35d/DAXPY_CUDA4.nsys-rep': File exists.\n",
      "Use `--force-overwrite true` to overwrite existing files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-2eb7.qdstrm'\n",
      "[1/1] [========================100%] nsys-report-2791.nsys-rep\n",
      "Generated:\n",
      "\t/tmp/nsys-report-2791.nsys-rep\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nsys profile  -o CUDA_max4 ./CUDA_max4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
